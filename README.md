## Glide

Glide Attention is a hybrid attention mechanism that improves the efficiency of transformer models by combining Gated Linear Attention (GLA) with Sliding Window Softmax Attention.

<img src="assert/Glide.png" width="600" alt="Glide Architecture">

